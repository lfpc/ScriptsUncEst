{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc22576-5820-4a9d-8331-2022de451b0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libs and pre-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c22a616-cf56-40b9-ac29-5fc2bd50d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "REPOSITORY_PATH = r'/home/luis-felipe/UncEst'\n",
    "DATA_PATH = os.path.join(REPOSITORY_PATH,'data')\n",
    "#CORRUPTED_DATA_PATH = os.path.join(DATA_PATH,'corrupted')\n",
    "\n",
    "PATH_MODELS = os.path.join(REPOSITORY_PATH,'torch_models')\n",
    "PATH_TRAINER = os.path.join(PATH_MODELS,'trainer')\n",
    "\n",
    "PATH_FIGS = os.path.join(REPOSITORY_PATH,'figs','MCDropout')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7101e-0263-42e0-b290-03de36165ad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bibliotecas padrões python e utils pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e681b-161b-4c1b-b471-13545dce356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c476911-a1b3-4c63-8cf6-cfd052f8763f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contrário\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89727b-1d1e-4bb5-8ff9-e6101e9ee724",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bibliotecas desenvolvidas\n",
    "\n",
    "https://github.com/lfpc/Uncertainty_Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8edd47e-4c11-431e-ac71-789e1340f377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NN_models as models\n",
    "import NN_utils as utils\n",
    "import NN_utils.train_and_eval as TE\n",
    "import torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ddd3b91-2ce1-42ed-b5db-153f33cba5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uncertainty.metrics as metrics\n",
    "from uncertainty.MonteCarlo_Dropout import MonteCarloDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafa55c-cb79-44a4-bb6f-c0d9f13c926a",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce415794-4119-4f02-8921-053cf4d8c64f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c3ed1f-b2c2-4910-b323-fd1fbec744d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "MODEL_ARC = 'VGG_16'\n",
    "DATA = 'Cifar100'\n",
    "NAME = MODEL_ARC +'_' + DATA + '_MCDropout'\n",
    "\n",
    "data = torch_data.__dict__[DATA](data_dir = DATA_PATH)\n",
    "model_class = models.__dict__[MODEL_ARC]\n",
    "\n",
    "weights_path = os.path.join(PATH_MODELS,MODEL_ARC,DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGTH_FILE = 0\n",
    "N_ENS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09517953-3fad-48bc-bc41-10f47034a776",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_files(weights_path):\n",
    "    #Get all weight files in weights_path\n",
    "    files = [f for f in os.listdir(weights_path) if os.path.isfile(os.path.join(weights_path, f)) and f.endswith(\".pt\")]\n",
    "    files = sorted(files)\n",
    "    return files\n",
    "\n",
    "def upload_weights(file, weights_path):\n",
    "    files = weights_files(weights_path)\n",
    "\n",
    "    if isinstance(file,int):\n",
    "        weights = files[file]\n",
    "        weights = os.path.join(weights_path,weights)\n",
    "    elif file == 'random':\n",
    "        weights = random.choice(files)\n",
    "        weights = os.path.join(weights_path,weights)\n",
    "    elif file == 'max':\n",
    "        return upload_weights(0, weights_path)\n",
    "    elif isinstance(file,str):\n",
    "        if file in files:\n",
    "            weights = os.path.join(weights_path,file)\n",
    "        elif file+'.pt' in files:\n",
    "            weights = os.path.join(weights_path,file+'.pt')\n",
    "        else: raise Exception(\"No file named \", file)\n",
    "    state_dict = torch.load(weights)\n",
    "    return state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class(num_classes = data.n_classes,softmax = True).to(dev)\n",
    "model.eval()\n",
    "model.load_state_dict(upload_weights(WEIGTH_FILE, weights_path))\n",
    "print(f'Acurácia (modelo determinístico): {TE.model_acc(model,data.test_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mcd = MonteCarloDropout(model,N_ENS, as_ensemble= True).to(dev)\n",
    "print(f'Acurácia (com MCD): {TE.model_acc(model_mcd,data.test_dataloader, set_eval = False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafd86e-a9cf-45f7-950d-8bb2c93c0fa5",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db9827",
   "metadata": {},
   "source": [
    "### Deterministic Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9cf1e",
   "metadata": {},
   "source": [
    "#### Risk x Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mcd_det = MonteCarloDropout(model,N_ENS, as_ensemble= False).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98e33c31-8653-4cc8-9eab-3d635cea5cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC = metrics.selective_metrics(model_mcd_det,data.test_dataloader)\n",
    "for N_ENS in range(1,20):\n",
    "    model_mcd_det.n_samples = N_ENS\n",
    "    RC.plot_ROC_and_RC(aurc = True)\n",
    "    plt.suptitle(f'M = {N_ENS}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01252729-336e-4199-ba24-50b40f9f3e12",
   "metadata": {},
   "source": [
    "#### Risk x M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179575a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = ['MCP (Ensemble)','MI','Best']\n",
    "#RC.set_uncs(uncs)\n",
    "f, axes = plt.subplots(1, len(uncs),sharey = True,figsize=(14,6),dpi=80)\n",
    "for N_ENS in range(1,20):\n",
    "    model_mcd_det.n_samples = N_ENS\n",
    "    RC.RC_curves()\n",
    "    for i,unc in enumerate(uncs):\n",
    "        if unc in RC.risk.keys():\n",
    "            axes[i].plot(RC.c_list,RC.risk[unc],label = f'M = {N_ENS}')\n",
    "        elif unc == 'Best':\n",
    "            axes[i].plot(RC.c_list,RC.get_best(),label = f'M = {N_ENS}')\n",
    "        else:\n",
    "            continue\n",
    "for i,unc in enumerate(uncs):\n",
    "    axes[i].set_title(uncs[i])\n",
    "    axes[i].set_xlabel(\"Coverage\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "    axes[i].tick_params(axis=\"x\",labelsize=RC.TICKS_FONTSIZE)\n",
    "    axes[i].grid()\n",
    "    axes[i].legend()\n",
    "axes[0].set_ylabel(\"Risk\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "plt.suptitle(f'Risk x Coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b67a1",
   "metadata": {},
   "source": [
    "#### ROC x M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = ['MCP (Ensemble)','MI']\n",
    "#RC.set_uncs(uncs)\n",
    "f, axes = plt.subplots(1, len(uncs),sharey = True,figsize=(14,6),dpi=80)\n",
    "for N_ENS in range(1,20):\n",
    "    model_mcd_det.n_samples = N_ENS\n",
    "    RC.ROC_curves()\n",
    "    for i,unc in enumerate(uncs):\n",
    "        if unc in RC.risk.keys():\n",
    "            axes[i].plot(RC.ROC[unc][0],RC.ROC[unc][1],label = f'M = {N_ENS}')\n",
    "        else: continue\n",
    "for i,unc in enumerate(uncs):\n",
    "    axes[i].set_title(uncs[i])\n",
    "    axes[i].set_xlabel(\"False Positive Rate\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "    axes[i].tick_params(axis=\"x\",labelsize=RC.TICKS_FONTSIZE)\n",
    "    axes[i].grid()\n",
    "    axes[i].legend()\n",
    "axes[0].set_ylabel(\"True Positive Rate\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "plt.suptitle(f'Curva ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c8055",
   "metadata": {},
   "source": [
    "### Ensemble (average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dca813",
   "metadata": {},
   "source": [
    "#### Risk x Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfade27",
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_dict = {}\n",
    "for N_ENS in range(1,20):\n",
    "    model_mcd.n_samples = N_ENS\n",
    "    RC = metrics.selective_metrics(model_mcd,data.test_dataloader)\n",
    "    RC.plot_ROC_and_RC(aurc = True)\n",
    "    RC_dict[N_ENS] = RC\n",
    "    plt.suptitle(f'M = {N_ENS}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3911a",
   "metadata": {},
   "source": [
    "#### Risk x M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = ['MCP','MI','Best']\n",
    "#RC.set_uncs(uncs)\n",
    "f, axes = plt.subplots(1, len(uncs),sharey = True,figsize=(14,6),dpi=80)\n",
    "for N_ENS,RC in RC_dict.items():\n",
    "    for i,unc in enumerate(uncs):\n",
    "        if unc in RC.risk.keys():\n",
    "            axes[i].plot(RC.c_list,RC.risk[unc],label = f'M = {N_ENS}')\n",
    "        elif unc == 'Best':\n",
    "            axes[i].plot(RC.c_list,RC.get_best(),label = f'M = {N_ENS}')\n",
    "        else:\n",
    "            continue\n",
    "for i,unc in enumerate(uncs):\n",
    "    axes[i].set_title(uncs[i])\n",
    "    axes[i].set_xlabel(\"Coverage\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "    axes[i].tick_params(axis=\"x\",labelsize=RC.TICKS_FONTSIZE)\n",
    "    axes[i].grid()\n",
    "    axes[i].legend()\n",
    "axes[0].set_ylabel(\"Risk\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "plt.suptitle(f'Risk x Coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19999e",
   "metadata": {},
   "source": [
    "#### ROC x M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncs = ['MCP','MI']\n",
    "#RC.set_uncs(uncs)\n",
    "f, axes = plt.subplots(1, len(uncs),sharey = True,figsize=(14,6),dpi=80)\n",
    "for N_ENS,RC in RC_dict.items():\n",
    "    for i,unc in enumerate(uncs):\n",
    "        if unc in RC.risk.keys():\n",
    "            axes[i].plot(RC.ROC[unc][0],RC.ROC[unc][1],label = f'M = {N_ENS}')\n",
    "        else: continue\n",
    "for i,unc in enumerate(uncs):\n",
    "    axes[i].set_title(uncs[i])\n",
    "    axes[i].set_xlabel(\"False Positive Rate\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "    axes[i].tick_params(axis=\"x\",labelsize=RC.TICKS_FONTSIZE)\n",
    "    axes[i].grid()\n",
    "    axes[i].legend()\n",
    "axes[0].set_ylabel(\"True Positive Rate\", fontsize=RC.LABEL_FONTSIZE*0.7)\n",
    "plt.suptitle(f'Curva ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a25d1",
   "metadata": {},
   "source": [
    "### Ensemble x Deterministic Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f4b0b",
   "metadata": {},
   "source": [
    "#### RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b77d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8939ae6302d706547273c597dd3be7d36d3b4c2b9aa367c9a420125c13753bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
