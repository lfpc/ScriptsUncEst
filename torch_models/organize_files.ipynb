{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662d8c08-7225-4cbe-9bc4-fccdda15da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "REPOSITORY_PATH = r'/home/luis-felipe/UncEst'\n",
    "DATA_PATH = os.path.join(REPOSITORY_PATH,'data')\n",
    "#CORRUPTED_DATA_PATH = os.path.join(DATA_PATH,'corrupted')\n",
    "\n",
    "PATH_MODELS = os.path.join(REPOSITORY_PATH,'torch_models')\n",
    "PATH_TRAINER = os.path.join(PATH_MODELS,'trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65e2330-6398-481f-8e37-5075d050052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch_data\n",
    "import NN_utils\n",
    "import torch.nn.functional as F\n",
    "from NN_utils import train_and_eval as TE\n",
    "import NN_models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e8d9f4-af46-4b2c-abed-3d166a7e9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contrário\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98d53d-8bec-4dfc-a207-8fe8973f7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARC = 'CNN8'\n",
    "DATA = 'Cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408c9db-cfe7-482b-b0b2-5e64c6aa1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = os.path.join(PATH_MODELS,MODEL_ARC,DATA)\n",
    "data = data = torch_data.__dict__[DATA](data_dir = DATA_PATH,download = False)\n",
    "model_class = models.__dict__[MODEL_ARC]\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f)) and f.endswith(\".pt\")]\n",
    "onlyfiles = sorted(onlyfiles)\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281636c7-7830-4025-85b8-ddaedc6e9edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_by_acc(files,new_name_def = None, path = mypath):\n",
    "    ''' Salva os modelos em ordem de acurácia (modelo 0 é o com maior acurácia e etc)'''\n",
    "    model = model_class(num_classes = data.n_classes).to(dev)\n",
    "    if new_name_def is None:\n",
    "        new_name_def = model.name\n",
    "    d = {}\n",
    "    for s in files:\n",
    "        state_dict = torch.load(os.path.join(mypath,s))\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        acc = TE.model_acc(model,data.test_dataloader)\n",
    "        d[s] = acc\n",
    "    d = dict(sorted(d.items(), key=lambda item: item[1],reverse=True))\n",
    "    for i,s in enumerate(d):\n",
    "        new_name = new_name_def + '_'+str(i)+'.pt'\n",
    "        if os.path.isfile(os.path.join(mypath,new_name)):\n",
    "            os.rename(os.path.join(mypath,new_name), os.path.join(mypath,new_name+'y'))\n",
    "            d[new_name] += 'y'\n",
    "        os.rename(os.path.join(mypath,s), os.path.join(mypath,new_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8be2a9-ef31-48a7-b32c-028eee23ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = MODEL_ARC +'_' + DATA \n",
    "sort_by_acc(onlyfiles,NAME)\n",
    "onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f)) and f.endswith(\".pt\")]\n",
    "onlyfiles = sorted(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dbe6a-e216-42ac-9288-3f4e6b805397",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(mypath,\"models_results.txt\"), \"w\") as text_file:\n",
    "    '''Salva txt com acurácias de cada um'''\n",
    "    model = model_class(num_classes = data.n_classes).to(dev)\n",
    "    for s in onlyfiles:\n",
    "        print(s)\n",
    "        state_dict = torch.load(os.path.join(mypath,s))\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        acc = TE.model_acc(model,data.test_dataloader)\n",
    "        print(f\"Acurácia: {acc}\")\n",
    "        print(f\"Acurácia de {s}: {acc}\", file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8113e-45b6-4acd-b52f-90761929ed9f",
   "metadata": {},
   "source": [
    "# change layers name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55a0b9-2755-4474-bbdc-f6563e49e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "if False:\n",
    "    '''Alguns modelos foram treinados com a arquitetura antiga com o nome  diferente em algumas camadas'''\n",
    "    for s in onlyfiles:\n",
    "        state_dict = torch.load(os.path.join(mypath,s))\n",
    "        state_dict = OrderedDict((\"classifier_layer.weight\" if k == 'classifier_layer.0.weight' else k, v) for k, v in state_dict.items())\n",
    "        state_dict = OrderedDict((\"classifier_layer.bias\" if k == 'classifier_layer.0.bias' else k, v) for k, v in state_dict.items())\n",
    "        torch.save(state_dict,os.path.join(mypath,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e2b0f-6b68-42ed-89f6-d7ae141c18bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2f689f-9847-451e-8f9a-d0999da1acc8",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d082ba23-899a-46ec-8a14-baf724874e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty.mimo import MIMO_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b83c7267-330f-4966-a74b-d5842f9dab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'MIMO_CNN8_3_2_100.pt'.endswith(\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4a2d2f9-6c1c-432f-b3ea-1b2ee540d8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN8',\n",
       " 'organize_files.ipynb',\n",
       " 'MIMO_CNN8_3_10.pt',\n",
       " 'MIMO_CNN8_3_2_100.pt',\n",
       " 'MIMO_CNN8_3_1_10.pt',\n",
       " 'WideResNet',\n",
       " 'MIMO_CNN8_3_2_10.pt',\n",
       " 'trainer',\n",
       " 'MIMO_CNN8_3_100.pt',\n",
       " 'VGG_16',\n",
       " '.ipynb_checkpoints',\n",
       " 'MIMO_CNN8_3_1_100.pt']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd90926d-3ac2-458c-b408-d8af553bff58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIMO_CNN8_3_10.pt',\n",
       " 'MIMO_CNN8_3_100.pt',\n",
       " 'MIMO_CNN8_3_1_10.pt',\n",
       " 'MIMO_CNN8_3_1_100.pt',\n",
       " 'MIMO_CNN8_3_2_10.pt',\n",
       " 'MIMO_CNN8_3_2_100.pt']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f for f in os.listdir(PATH_MODELS) if os.path.isfile(os.path.join(PATH_MODELS, f)) and f.endswith(\".pt\")]\n",
    "onlyfiles = sorted(onlyfiles)\n",
    "onlyfiles = onlyfiles\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "463901e6-1148-4e5b-add3-ebcdc32d7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'Cifar10'\n",
    "MODEL_ARC = 'CNN8'\n",
    "data = torch_data.__dict__[DATA](data_dir = DATA_PATH,download = False)\n",
    "model_class = models.__dict__[MODEL_ARC]\n",
    "mypath = os.path.join(PATH_MODELS,MODEL_ARC,DATA,'MIMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0130bbfa-adb1-4fe0-9705-e201f30bdefc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMO_CNN8_3_10.pt\n",
      "Acurácia: 85.8\n",
      "MIMO_CNN8_3_1_10.pt\n",
      "Acurácia: 83.91\n",
      "MIMO_CNN8_3_2_10.pt\n",
      "Acurácia: 86.17\n"
     ]
    }
   ],
   "source": [
    "for N_ENS in [3]:\n",
    "    #N_ENS = 3\n",
    "    NAME = 'MIMO_' + str(N_ENS)+'_' + MODEL_ARC+ '_' + DATA + '.pt'\n",
    "    model = MIMO_ensemble(model_class,data.n_classes, n_ensembles = N_ENS, softmax = True).to(dev)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for s in onlyfiles:\n",
    "            max_acc = 0\n",
    "            if 'VGG' in s:\n",
    "                continue\n",
    "            if '100' in s:\n",
    "                continue\n",
    "            if not '_'+str(N_ENS) in s:\n",
    "                continue\n",
    "\n",
    "            print(s)\n",
    "            state_dict = torch.load(os.path.join(PATH_MODELS,s))\n",
    "            model.load_state_dict(state_dict)\n",
    "            acc = TE.model_acc(model,data.test_dataloader)\n",
    "            if acc>max_acc:\n",
    "                max_acc = acc\n",
    "                max_s = s\n",
    "            print(f\"Acurácia: {acc}\")\n",
    "        torch.save(torch.load(os.path.join(PATH_MODELS,max_s)), os.path.join(mypath,NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11fb64-1ee6-42ac-a774-5e6181655bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
